{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d06541f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f02a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d39209",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Neural Networks with Keras\n",
    "\n",
    "\"ANNs are at the very core of Deep Learning. They are versatile, powerful, and scalable,making them ideal to tackle large and highly complex Machine Learning tasks such as classifying billions of images (e.g., Google Images), powering speech recognition services (e.g., Apple’s Siri), recommending the best videos to watch to hundreds of millions of users every day (e.g., YouTube), or learning to beat the world champion at the game of Go (DeepMind’s AlphaGo).\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e476fe9",
   "metadata": {},
   "source": [
    "# From Biological to Artificial Neurons\n",
    "\n",
    "Will ANN's die again? Probably not: \n",
    "- There is now a huge quantity of data available to train neural networks, and ANNs frequently outperform other ML techniques on very large and complex problems.\n",
    "- The tremendous increase in computing power since the 1990s now makes it possible to train large neural networks in a reasonable amount of time. This is in part due to Moore’s law (the number of components in integrated circuits has doubled about every 2 years over the last 50 years), but also thanks to the gaming industry, which has stimulated the production of powerful GPU cards by the millions. Moreover, cloud platforms have made this power accessible to everyone.\n",
    "- The training algorithms have been improved. To be fair they are only slightly different from the ones used in the 1990s, but these relatively small tweaks have had a huge positive impact.\n",
    "- Some theoretical limitations of ANNs have turned out to be benign in practice. For example, many people thought that ANN training algorithms were doomed because they were likely to get stuck in local optima, but it turns out that this is rather rare in practice (and when it is the case, they are usually fairly close to the global optimum).\n",
    "- ANNs seem to have entered a virtuous circle of funding and progress. Amazing products based on ANNs regularly make the headline news, which pulls more and more attention and funding toward them, resulting in more and more progress and even more amazing products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779612e2",
   "metadata": {},
   "source": [
    "# Biological Neurons\n",
    "\n",
    "Skimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a80121",
   "metadata": {},
   "source": [
    "# Logiacal Computations with Neurons \n",
    "\n",
    "![title](images/logical_comp.png)\n",
    "\n",
    "Let’s see what these networks do:\n",
    "- The first network on the left is the identity function: if neuron A is activated,then neuron C gets activated as well (since it receives two input signals from neuron A); but if neuron A is off, then neuron C is off as well.     \n",
    "- The second network performs a logical AND: neuron C is activated only when     both neurons A and B are activated (a single input signal is not enough to activate neuron C). \n",
    "- The third network performs a logical OR: neuron C gets activated if either neuron A or neuron B is activated (or both).     \n",
    "- Finally, if we suppose that an input connection can inhibit the neuron’s activity (which is the case with biological neurons), then the fourth network computes a slightly more complex logical proposition: neuron C is activated only if neuron A  is active and neuron B is off. If neuron A is active all the time, then you get a logical NOT: neuron C is active when neuron B is off, and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096bbca8",
   "metadata": {},
   "source": [
    "# The Perceptron\n",
    "\n",
    "![title](images/perceptron.png)\n",
    "![title](images/perceptron_2.png)\n",
    "\n",
    "A single TLU can be used for simple linear binary classification. It computes a linear combination of the inputs, and if the result exceeds a threshold, it outputs the positive class. Otherwise it outputs the negative class (just like a Logistic Regression or linear SVM classifier).\n",
    "\n",
    "A **Perceptron** is simply composed of a **single layer of TLUs**, with each TLU connected to all the inputs. When all the neurons in a layer are connected to every neuron in the previous layer (i.e., its input neurons), the layer is called a fully connected layer, or a **dense layer**. The inputs of the Perceptron are fed to special passthrough neurons called input neurons: they output whatever input they are fed. All the input neurons form the input layer. Moreover, an extra bias feature is generally added (x0 = 1): it is\n",
    "typically represented using a special type of neuron called a bias neuron, which outputs 1 all the time.\n",
    "\n",
    "![title](images/perceptron_3.png)\n",
    "![title](images/perceptron_4.png) \n",
    "\n",
    "In this equation:\n",
    "- As always, X represents the matrix of input features. It has one row per instanceand one column per feature.\n",
    "- The weight matrix W contains all the connection weights except for the ones from the bias neuron. It has one row per input neuron and one column per artificialneuron in the layer.\n",
    "- The bias vector b contains all the connection weights between the bias neuronand the artificial neurons. It has one bias term per artificial neuron.\n",
    "- The function ϕ is called the activation function: when the artificial neurons areTLUs, it is a step function (but we will discuss other activation functions shortly).\n",
    "\n",
    "So, how is a Perceptron trained? The Perceptron training algorithm proposed by\n",
    "Rosenblatt was largely inspired by Hebb’s rule. In his 1949 book The Organization of Behavior (Wiley), Donald Hebb suggested that when a biological neuron triggers another neuron often, the connection between these two neurons grows stronger. Siegrid Löwel later summarized Hebb’s idea in the catchy phrase, **“Cells that fire together, wire together”**; that is, the connection weight between two neurons tends to increase when they fire simultaneously\n",
    "\n",
    "**Perceptrons are trained using a variant of this rule that takes into account the error made by the network when it makes a prediction; the Perceptron learning rule reinforces connections that help reduce the error**. More specifically, the Perceptron is fed one training instance at a time, and for each instance it makes its predictions. For every output neuron that produced a wrong prediction, it reinforces the connection weights from the inputs that would have contributed to the correct prediction.\n",
    "\n",
    "![title](images/perceptron_5.png) \n",
    "\n",
    "In this equation:\n",
    "- wi, j is the connection weight between the ith input neuron and the jth output neuron.\n",
    "- xi is the ith input value of the current training instance.\n",
    "- y j is the output of the jth output neuron for the current training instance.\n",
    "- yj is the target output of the jth output neuron for the current training instance.\n",
    "- η is the learning rate.\n",
    "\n",
    "**The decision boundary of each output neuron is linear, so Perceptrons are incapable of learning complex patterns** (just like Logistic Regression classifiers). However, **if the training instances are linearly separable**, Rosenblatt demonstrated that this algorithm would converge to a solution. This is called the **Perceptron convergence theorem**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13440dfa",
   "metadata": {},
   "source": [
    "Scikit-Learn provides a Perceptron class that implements a single-TLU network. It can be used pretty much as you would expect—for example, on the iris dataset (introduced in Chapter 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1772545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(int)\n",
    "\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562a5bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eed57bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure perceptron_iris_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "save_fig(\"perceptron_iris_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1382b",
   "metadata": {},
   "source": [
    "You may have noticed that the Perceptron learning algorithm strongly resembles Stochastic Gradient Descent. In fact, Scikit-Learn’s Perceptron class is equivalent to using an SGDClassifier with the following hyperparameters: loss=\"perceptron\", learning_rate=\"constant\", eta0=1 (the learning rate), and penalty=None (no regularization).\n",
    "\n",
    "Note that contrary to Logistic Regression classifiers, Perceptrons do not output a class probability; rather, they make predictions based on a hard threshold. This is one reason to prefer Logistic Regression over Perceptrons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14b2fa",
   "metadata": {},
   "source": [
    "#### Limitations \n",
    "In their 1969 monograph Perceptrons, Marvin Minsky and Seymour Papert highlighted a number of serious weaknesses of Perceptrons—in particular, the fact that they are incapable of solving some trivial problems (e.g., the Exclusive OR (XOR) classification problem).\n",
    "\n",
    "#### The Solution\n",
    "It turns out that some of the limitations of Perceptrons can be eliminated by stacking multiple Perceptrons. The resulting ANN is called a Multilayer Perceptron (MLP). An MLP can solve the XOR problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ad240",
   "metadata": {},
   "source": [
    "# The Multilayer Perceptron and Backpropagation\n",
    "\n",
    "An MLP is composed of one (passthrough) input layer, one or more layers of TLUs, called hidden layers, and one final layer of TLUs called the output layer (see Figure 10-7). The layers close to the input layer are usually called the lower layers, and the ones close to the outputs are usually called the upper layers. Every layer except the output layer includes a bias neuron and is fully connected to the next layer.\n",
    "\n",
    "![title](images/mlp_1.png) \n",
    "\n",
    "**NOTE:** The signal flows only in one direction (from the inputs to the outputs),\n",
    "so this architecture is an example of a **feedforward neural network\n",
    "(FNN).**\n",
    "\n",
    "When an ANN contains a deep stack of hidden layers,9 it is called a **deep neural network (DNN).** The field of Deep Learning studies DNNs, and more generally models containing deep stacks of computations. Even so, many people talk about Deep Learning whenever neural networks are involved (even shallow ones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e254f",
   "metadata": {},
   "source": [
    "For many years researchers struggled to find a way to train MLPs, without success. But in 1986, David Rumelhart, Geoffrey Hinton, and Ronald Williams published a groundbreaking paper that introduced the **backpropagation training algorithm**, which is still used today. **In short, it is Gradient Descent using an efficient technique for computing the gradients automatically: in just two passes through the network (one forward, one backward), the backpropagation algorithm is able to compute the gradient of the network’s error with regard to every single model parameter.** In other words, it can find out how each connection weight and each bias term should be tweaked in order to reduce the error. Once it has these gradients, it just performs a regular Gradient Descent step, and the whole process is repeated until the network converges to the solution.\n",
    "\n",
    "**NOTE:** Automatically computing gradients is called automatic differentiation,\n",
    "or autodiff. There are various autodiff techniques, with different\n",
    "pros and cons. The one used by backpropagation is called\n",
    "reverse-mode autodiff. It is fast and precise, and is well suited when\n",
    "the function to differentiate has many variables (e.g., connection\n",
    "weights) and few outputs (e.g., one loss). \n",
    "\n",
    "### Backpropagation in More Detail\n",
    "\n",
    "Let’s run through this algorithm in a bit more detail:\n",
    "- It handles one mini-batch at a time (for example, containing 32 instances each), and it goes through the full training set multiple times. Each pass is called an epoch.\n",
    "- Each mini-batch is passed to the network’s input layer, which sends it to the first hidden layer. The algorithm then computes the output of all the neurons in this layer (for every instance in the mini-batch). The result is passed on to the next layer, its output is computed and passed to the next layer, and so on until we get the output of the last layer, the output layer. This is the forward pass: it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass.\n",
    "- Next, the algorithm measures the network’s output error (i.e., it uses a loss function that compares the desired output and the actual output of the network, and returns some measure of the error).\n",
    "- Then it computes how much each output connection contributed to the error. This is done analytically by applying the chain rule (perhaps the most fundamental rule in calculus), which makes this step fast and precise.\n",
    "- The algorithm then measures how much of these error contributions came from each connection in the layer below, again using the chain rule, working backward until the algorithm reaches the input layer. As explained earlier, this reverse pass efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward through the network (hence the name of the algorithm).\n",
    "- Finally, the algorithm performs a Gradient Descent step to tweak all the connection weights in the network, using the error gradients it just computed.\n",
    "\n",
    "**SUMMARY:** This algorithm is so important that it’s worth summarizing it again: for each training instance, the backpropagation algorithm first makes a prediction (forward pass) and measures the error, then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally tweaks the connection weights to reduce the error (Gradient Descent step).\n",
    "\n",
    "**WARNING:** It is important to initialize all the hidden layers’ connection weights randomly, or else training will fail. For example, if you initialize all weights and biases to zero, then all neurons in a given layer will be perfectly identical, and thus backpropagation will affect them in exactly the same way, so they will remain identical. In other words, despite having hundreds of neurons per layer, your model will act as if it had only one neuron per layer: it won’t be too smart. If instead you randomly initialize the weights, you break the symmetry and allow backpropagation to train a diverse team of neurons.\n",
    "\n",
    "### Popular Activation Functions\n",
    "- logistic (sigmoid) function, σ(z) = 1 / (1 + exp(–z)).\n",
    "- The hyperbolic tangent function: tanh(z) = 2σ(2z) – 1\n",
    "- The Rectified Linear Unit function: ReLU(z) = max(0, z)\n",
    "\n",
    "### Why do we need activation functions in the first place? \n",
    "Well, if you chain several linear transformations, all you get is a linear transformation. For example, if f(x) = 2x + 3 and g(x) = 5x – 1, then chaining these two linear functions gives you another linear function: f(g(x)) = 2(5x – 1) + 3 = 10x + 1. So if you don’t have some nonlinearity between layers, then even a deep stack of layers is equivalent to a single layer, and you can’t solve very complex problems with that. Conversely, a large enough DNN with nonlinear activations can theoretically approximate any continuous function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a130a43",
   "metadata": {},
   "source": [
    "# Regression MLP's\n",
    "\n",
    "First, MLPs can be used for regression tasks. If you want to predict a single value (e.g., the price of a house, given many of its features), then you just need a single output neuron: its output is the predicted value. For multivariate regression (i.e., to predict multiple values at once), you need one output neuron per output dimension\n",
    "\n",
    "In general, when building an MLP for regression, you do not want to use any activation function for the output neurons, so they are free to output any range of values. If you want to guarantee that the output will always be positive, then you can use the ReLU activation function in the output layer. Alternatively, you can use the softplus activation function, which is a smooth variant of ReLU: softplus(z) = log(1 + exp(z)). It is close to 0 when z is negative, and close to z when z is positive. Finally, if you want to guarantee that the predictions will fall within a given range of values, then you can use the logistic function or the hyperbolic tangent, and then scale the labels to the appropriate range: 0 to 1 for the logistic function and –1 to 1 for the hyperbolic tangent.\n",
    "\n",
    "The loss function to use during training is typically the mean squared error, but if you\n",
    "have a lot of outliers in the training set, you may prefer to use the mean absolute\n",
    "error instead. Alternatively, you can use the Huber loss, which is a combination of\n",
    "both.\n",
    "\n",
    "**NOTE:** The Huber loss is quadratic when the error is smaller than a threshold\n",
    "δ (typically 1) but linear when the error is larger than δ. The\n",
    "linear part makes it less sensitive to outliers than the mean squared\n",
    "error, and the quadratic part allows it to converge faster and be\n",
    "more precise than the mean absolute error.\n",
    "\n",
    "![title](images/mlp_reg.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297eb398",
   "metadata": {},
   "source": [
    "# Classification MLPs\n",
    "\n",
    "MLPs can also be used for classification tasks. For a binary classification problem, you just need a single output neuron using the logistic activation function: the output will be a number between 0 and 1, which you can interpret as the estimated probability of the positive class. The estimated probability of the negative class is equal to one minus that number.\n",
    "\n",
    "MLPs can also easily handle multilabel binary classification tasks (see Chapter 3). For example, you could have an email classification system that predicts whether each incoming email is ham or spam, and simultaneously predicts whether it is an urgent or nonurgent email. In this case, you would need two output neurons, both using the logistic activation function: the first would output the probability that the email is spam, and the second would output the probability that it is urgent. More generally, you would dedicate one output neuron for each positive class. Note that the output probabilities do not necessarily add up to 1. This lets the model output any combination of labels: you can have nonurgent ham, urgent ham, nonurgent spam, and perhaps even urgent spam (although that would probably be an error).\n",
    "\n",
    "If each instance can belong only to a single class, out of three or more possible classes (e.g., classes 0 through 9 for digit image classification), then you need to have one output neuron per class, and you should use the softmax activation function for the whole output layer (see Figure 10-9). The softmax function (introduced in Chapter 4) will ensure that all the estimated probabilities are between 0 and 1 and that they add up to 1 (which is required if the classes are exclusive). This is called multiclass classification.\n",
    "\n",
    "![title](images/mlp_cla_1.png) \n",
    "\n",
    "![title](images/mlp_cla_2.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79acfa76",
   "metadata": {},
   "source": [
    "**TIP:** Before we go on, I recommend you go through exercise 1 at the  \n",
    "end of this chapter. You will play with various neural network  \n",
    "architectures and visualize their outputs using the TensorFlow Playground.  \n",
    "This will be very useful to better understand MLPs, including  \n",
    "the effects of all the hyperparameters (number of layers and  \n",
    "neurons, activation functions, and more).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_learning] *",
   "language": "python",
   "name": "conda-env-ml_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
